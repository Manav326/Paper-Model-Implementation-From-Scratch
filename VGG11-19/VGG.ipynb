{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGG.ipynb","provenance":[],"authorship_tag":"ABX9TyP8qCUjKuh/hJoLd3YFghhD"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"g-w0JomkSiZZ","colab_type":"text"},"source":["# Imagenet\n","ImageNet, is a dataset of over 15 millions labeled high-resolution images with around 22,000 categories. ILSVRC uses a subset of ImageNet of around 1000 images in each of 1000 categories. In all, there are roughly 1.3 million training images, 50,000 validation images and 100,000 testing images.\n","\n","* Main idea was as the depth of the network increase error decreases\n","\n","* Second position in  ILSVRC 2014\n","\n","# Why VGG16\n","\n","* By using 2 layers of 3×3 filters, it actually have already covered 5×5 area. By using 3 layers of 3×3 filters, it actually have already covered 7×7 effective area. Thus, large-size filters such as 11×11 in AlexNet and 7×7 in ZFNetindeed are not needed.\n","\n","* Another reason is that the number of parameters are fewer.\n","\n","For example:\n","1 layer of 11×11 filter, number of parameters = 11×11=121M<br>\n","5 layer of 3×3 filter, number of parameters = 3×3×5=45<br>\n","   Number of parameters is reduced by 63%<br>\n","<br>\n","\n","1 layer of 7×7 filter, number of parameters = 7×7=49<br>\n","3 layers of 3×3 filters, number of parameters = 3×3×3=27<br>\n","Number of parameters is reduced by 45%<br>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"DIPEcCmjZTny","colab_type":"text"},"source":["# Shortcomings of VGG\n","\n","* can have vanishing gradient problem due to deeper network\n","\n","* More training time and inference time.\n","\n","* It has so many weight parameters \n"]},{"cell_type":"markdown","metadata":{"id":"Y7a2oJS-ZTqj","colab_type":"text"},"source":["\n","\n","---\n","\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dcW84R8ZwuJ5","colab_type":"text"},"source":["In this notebook we will implemnet VGG network from scratch. We will make a common implementation in which we can call any of VGG11,VGG13,VGG16,VGG19 accordingly. <br>\n"]},{"cell_type":"code","metadata":{"id":"eIXEbesUsw0z","colab_type":"code","colab":{}},"source":["import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import requests\n","import os\n","from torch.hub import load_state_dict_from_url"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cUHlUvSzCc6w","colab_type":"code","colab":{}},"source":["channel_dict = {'vgg11' : [64,'MP',128,'MP',256,256,'MP',512,512,'MP',512,512,'MP'],\n","'vgg13' : [64, 64, 'MP', 128, 128, 'MP', 256, 256, 'MP', 512, 512, 'MP', 512, 512, 'MP'],\n","'vgg16' :  [64, 64, 'MP', 128, 128, 'MP', 256, 256, 256, 'MP', 512, 512, 512, 'MP', 512, 512, 512, 'MP'],\n","'vgg19' : [64, 64, 'MP', 128, 128, 'MP', 256, 256, 256, 256, 'MP', 512, 512, 512, 512, 'MP', 512, 512, 512, 512, 'MP']}\n","\n","\n","weight_urls = {\n","    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n","    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n","    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n","    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n","    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n","    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n","    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n","    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EpftzTrJzRgf","colab_type":"code","colab":{}},"source":["# utiliy functions\n","def create_layers(channel_list,batch_norm=False):\n","  seq_list = []\n","  input_channels = 3\n","  for channel in channel_list:\n","    if channel == 'MP':\n","      seq_list.append(nn.MaxPool2d(kernel_size=2,stride=2))\n","    else:\n","      conv_layer = nn.Conv2d(in_channels = input_channels, kernel_size=3, out_channels=channel, stride=1)\n","      if batch_norm:\n","        bn = nn.BatchNorm2d(channel)\n","        seq_list.extend([conv_layer,bn,nn.ReLU(inplace=True)])\n","      else:\n","        seq_list.extend([conv_layer,nn.ReLU(inplace=True)])\n","          \n","      input_channels = channel\n","\n","  return nn.Sequential(*seq_list)\n","\n","\n","# function which helps to load the weights\n","def load_weights(model,weight_url):\n","    state_dict = load_state_dict_from_url(weight_url)\n","    model.load_state_dict(state_dict)\n","    return model\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nUgcohHttSUq","colab_type":"code","colab":{}},"source":["class VGG(nn.Module):\n","  def __init__(self,model,batch_norm=False, weight_initialize=True):\n","    super(VGG, self).__init__()\n","    if batch_norm:\n","        self.features = create_layers(channel_dict[model],batch_norm=True)\n","    else:\n","        self.features = create_layers(channel_dict[model],batch_norm=False)\n","    self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n","    \n","\n","    num_classes = 1000\n","    self.classifier = nn.Sequential(\n","        nn.Linear(512 * 7 * 7, 4096),\n","        nn.ReLU(True),\n","        nn.Dropout(),\n","        nn.Linear(4096, 4096),\n","        nn.ReLU(True),\n","        nn.Dropout(),\n","        nn.Linear(4096, num_classes),\n","        )    \n","  \n","    if weight_initialize:\n","        self._initialize_weights()\n","    \n","  def forward(self,x):\n","      x = self.features(x)\n","      x = self.avgpool(x)\n","      x = torch.flatten(x,1)\n","      x = self.classifier(x)\n","      return x\n","\n","\n","  def _initialize_weights(self):\n","      for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","                if m.bias is not None:\n","                    nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.normal_(m.weight, 0, 0.01)\n","                nn.init.constant_(m.bias, 0)\n","\n","\n","   "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wnztrH6wwe2F","colab_type":"text"},"source":["# Normal initialization of model"]},{"cell_type":"code","metadata":{"id":"ucKT3EQy4MIQ","colab_type":"code","outputId":"494222ff-073d-4f7a-9979-da99c910fb92","executionInfo":{"status":"ok","timestamp":1591700729538,"user_tz":-330,"elapsed":4325,"user":{"displayName":"Arun U","photoUrl":"","userId":"02532826008740950037"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","model = VGG(model='vgg16',batch_norm=True,weight_initialize=True)\n","model"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n","    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n","    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU(inplace=True)\n","    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n","    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (16): ReLU(inplace=True)\n","    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n","    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (19): ReLU(inplace=True)\n","    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n","    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n","    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (26): ReLU(inplace=True)\n","    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n","    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (29): ReLU(inplace=True)\n","    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n","    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (32): ReLU(inplace=True)\n","    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n","    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (36): ReLU(inplace=True)\n","    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n","    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (39): ReLU(inplace=True)\n","    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n","    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (42): ReLU(inplace=True)\n","    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"JjNDU9E9wiyx","colab_type":"text"},"source":["# Loading pretrained weights\n"]},{"cell_type":"code","metadata":{"id":"lFnlv9egXho1","colab_type":"code","outputId":"5f93ffee-8fd0-4469-ed1d-bb2954c0ce1d","executionInfo":{"status":"ok","timestamp":1591700800224,"user_tz":-330,"elapsed":5142,"user":{"displayName":"Arun U","photoUrl":"","userId":"02532826008740950037"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model = VGG(model='vgg16',batch_norm=True)\n","model = load_weights(model,weight_urls['vgg16_bn'])\n","model"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n","    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n","    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU(inplace=True)\n","    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n","    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (16): ReLU(inplace=True)\n","    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n","    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (19): ReLU(inplace=True)\n","    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n","    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n","    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (26): ReLU(inplace=True)\n","    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n","    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (29): ReLU(inplace=True)\n","    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n","    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (32): ReLU(inplace=True)\n","    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n","    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (36): ReLU(inplace=True)\n","    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n","    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (39): ReLU(inplace=True)\n","    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n","    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (42): ReLU(inplace=True)\n","    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":29}]}]}